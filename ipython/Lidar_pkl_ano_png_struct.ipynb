{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "142d9048-1920-423e-b035-bec30de9a3b8",
   "metadata": {},
   "source": [
    "# This is the script to explain how the LiDAR's pkl file and annotation's .png file should be constructed for using in CLFCN and CLFT nwtowrks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4084ead7-b4f4-4c87-9ac0-70203efc5eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import cv2\n",
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38c9ad06-2172-4573-8e0f-b1a913bd3ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "lidar_path = '../test_images/test_lidar.pkl'\n",
    "anno_path = '../test_images/test_anno.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "518fc7e4-1b54-4c03-a17c-392109bb433a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lidar_file = open(lidar_path, 'rb')\n",
    "lidar_data = pickle.load(lidar_file)\n",
    "lidar_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eaa803d-a8ed-4651-a801-8358b8e67cb2",
   "metadata": {},
   "source": [
    "### There are three dicts in .pkl file. '3d_points', 'class_instance', and 'camera_coordiantes' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5446e8b6-6246-4f99-8ea9-1533a804c701",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'3d_points': array([[-5.2509296e+01,  1.0832564e+01,  4.3221998e+00],\n",
       "        [-5.2449059e+01,  1.0953444e+01,  4.3208528e+00],\n",
       "        [-5.2428661e+01,  1.1082363e+01,  4.3210974e+00],\n",
       "        ...,\n",
       "        [-1.3185942e+00,  2.3033498e-01,  5.4545771e-02],\n",
       "        [-1.3414596e+00, -2.0684135e-01,  5.1952340e-02],\n",
       "        [-1.3731146e+00, -1.8327464e-01,  4.2206958e-02]], dtype=float32),\n",
       " 'class_instance': array([[5, 0],\n",
       "        [5, 0],\n",
       "        [5, 0],\n",
       "        ...,\n",
       "        [5, 0],\n",
       "        [5, 0],\n",
       "        [5, 0]], dtype=uint8),\n",
       " 'camera_coordinates': array([[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]], dtype=uint16)}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lidar_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "800d40ef-f068-4d0f-aea9-0f7663f253dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "155111\n",
      "76.0497\n",
      "-72.484505\n",
      "155111\n",
      "83\n",
      "0\n",
      "155111\n",
      "1919\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(len(lidar_data['3d_points']))\n",
    "print(np.max(lidar_data['3d_points']))\n",
    "print(np.min((lidar_data['3d_points'])))\n",
    "print(len(lidar_data['class_instance']))\n",
    "print(np.max(lidar_data['class_instance']))\n",
    "print(np.min((lidar_data['class_instance'])))\n",
    "print(len(lidar_data['camera_coordinates']))\n",
    "print(np.max(lidar_data['camera_coordinates']))\n",
    "print(np.min((lidar_data['camera_coordinates'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89333436-ca11-4ee2-8a18-0eaeb1452ab3",
   "metadata": {},
   "source": [
    "### From the max ad min of these three dicts, you can see the '3d_points' is the LiDAR's reading in meters, the 'class_instance' is the label of each LiDAR point (this is how Waymo label their data), and the 'camera_coordinates' is the LiDAR point's corresponding camera-projection's pixel coordination (the waymo's camera image is 1920x1080). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ae652e-9a5e-48af-a64e-a8ae9036fe3f",
   "metadata": {},
   "source": [
    "### Therefore, the most important part in this part is figuring out the 'LiDAR point's corresponding camera-projection'. This involves the camera-lidar extrinsic calibration to get the transforamtion matrix. But if use the large-scale open dataset, this has been done and usually the lidar-camera-projection is provided as 'range image'. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8921c1da-a1c6-4518-8839-09aa3417b5c7",
   "metadata": {},
   "source": [
    "### One more thing is for the waymo pkl file in this repo, it contains the 360 degrees LiDAR points and they fall on the 6 camera planes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "25281af6-a115-4859-9e63-273159215006",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5], dtype=uint16)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "camera_coord = lidar_data['camera_coordinates']\n",
    "points_3d = lidar_data['3d_points']\n",
    "np.unique(camera_coord[:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ac0bb0-f57d-492d-99d1-4e8a47ad435c",
   "metadata": {},
   "source": [
    "### But in the pipeline, only the front camera and corresponding LiDAR points are used. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4054566a-0603-471e-9f7a-f53f2be09c19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17223\n",
      "17223\n"
     ]
    }
   ],
   "source": [
    "# select camera front\n",
    "mask = camera_coord[:, 0] == 1\n",
    "front_points = points_3d[mask, :]\n",
    "front_camera_coord = camera_coord[mask, 1:3]\n",
    "print(len(front_points))\n",
    "print(len(front_camera_coord))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad3589f-3426-48ae-9c72-3cf382e91cc8",
   "metadata": {},
   "source": [
    "### Now for each point from LiDAR, there will be a camera-plane coordination. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5f538067-e377-4a54-beda-f90bcf705395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 65.50708   -14.290524    4.7711673]\n",
      "[1428  550]\n"
     ]
    }
   ],
   "source": [
    "print(front_points[100])\n",
    "print(front_camera_coord[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88e11e3-971f-4084-9587-eecf07ac57fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cced0b00-24f6-4019-922a-f524a044b455",
   "metadata": {},
   "source": [
    "### For annotaiton's png file, it is in size 480x320, becuase the size of the camera data's png file is also 480x320. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a7d202-912c-49dc-a872-cc4283c42281",
   "metadata": {},
   "source": [
    "### It is single channel and the pixel values are the class indices. In our case, 0->ignore, 1->vehicle, 2->pedestrian, 3->sign, 4->cyclist, 5->background. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "65816441-0ec1-4dce-b2e7-44bc64b11806",
   "metadata": {},
   "outputs": [],
   "source": [
    "anno = cv2.imread(anno_path, cv2.IMREAD_UNCHANGED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a3460572-eedd-4152-95d5-f2ea0d62a59c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(320, 480)\n",
      "[0 1 3 5]\n"
     ]
    }
   ],
   "source": [
    "print(anno.shape)\n",
    "print(np.unique(anno))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97db428f-9006-44e4-963b-a82b6cda14d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
